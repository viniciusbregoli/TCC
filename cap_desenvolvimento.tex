\chapter{Desenvolvimento}

Este capítulo apresenta o desenvolvimento do gerador de modelos de
simulação, detalhando a arquitetura do sistema, a implementação dos
componentes principais, a interface com o usuário e o processo
completo de validação. O desenvolvimento seguiu princípios de
modularidade, separação de responsabilidades e generalização,
buscando criar uma solução que pudesse ser aplicada a diferentes
domínios sem necessidade de parametrização manual. As escolhas
arquiteturais e de implementação foram norteadas pelos requisitos de
automatização, robustez e reprodutibilidade estabelecidos nos
objetivos do trabalho.

\section{Estrutura do Projeto}

O código-fonte do sistema está organizado em uma estrutura modular
que separa claramente as responsabilidades e facilita a manutenção e
extensão. A estrutura completa do projeto é apresentada a seguir:

\begin{verbatim}
main/
|-- venv/                    # Ambiente virtual Python
|-- bases/                   # Logs XES de entrada (gitignored)
|-- output/                  # Resultados gerados (gitignored)
|
|-- core/                    # Módulo principal
|   |-- __init__.py         # Exportações da API
|   |-- models.py           # Dataclasses
|   |-- log_analyzer.py     # Análise automática de logs
|   |-- process_mining.py   # Mineração de processos
|   |-- simulation.py       # Simulação de eventos discretos
|   |-- validation.py       # Validação de qualidade
|   |-- utils.py            # Funções auxiliares
|   |-- excel_to_xes.py     # Converte Excel para XES
|
|-- app/                    # Interface web Streamlit
|   |-- app.py              # Aplicação principal
|   |-- uploads/            # Arquivos XES carregados
|   |-- outputs/            # Resultados da interface
|
|-- test.py                 # Script de teste CLI
\end{verbatim}

\subsection{Organização dos Módulos}

A estrutura modular do projeto separa claramente as
responsabilidades:

\begin{itemize}
	\item \textbf{core/}: Contém toda a lógica de negócio do sistema, incluindo análise de logs, mineração de processos, simulação e validação
	\item \textbf{app/}: Interface web desenvolvida com Streamlit para facilitar o uso do sistema
	\item \textbf{bases/} e \textbf{output/}: Diretórios para dados de entrada e saída, respectivamente (ignorados pelo Git)
\end{itemize}

\section{Arquitetura do Sistema}

\subsection{Filosofia Arquitetural}

O Sim2Log-Core foi projetado seguindo uma \textbf{arquitetura em
camadas modular} com clara separação de responsabilidades. Esta
abordagem arquitetural fundamenta-se em princípios de engenharia de
software estabelecidos, incluindo Separação de Responsabilidades
(\textit{Separation of Concerns}), Princípio da Responsabilidade Única
(\textit{Single Responsibility Principle}) e Inversão de Dependências
(\textit{Dependency Inversion}). A arquitetura foi estruturada em cinco
camadas hierárquicas, conforme ilustrado na
Figura~\ref{fig:arquitetura_camadas}.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\textwidth]{figuras/arquitetura_camadas.png}
	\caption{Arquitetura em camadas do Sim2Log-Core. Fonte: Autor (2025)}
	\label{fig:arquitetura_camadas}
\end{figure}

\subsubsection{Camada 1: Interface de Usuário}

Esta camada fornece o ponto de acesso para usuários finais através de
um dashboard web interativo implementado com Streamlit. A interface
permite operações de upload, configuração, execução e visualização de
resultados sem necessidade de programação.

\subsubsection{Camada 2: Fachada}

Implementa o padrão de projeto Facade através da classe
\texttt{ProcessMiningPipeline}, que fornece uma interface simplificada
e unificada para o subsistema complexo. Esta camada oculta a
complexidade da coordenação entre os cinco componentes independentes,
oferecendo métodos de alto nível como \texttt{run\_full\_pipeline()} e
\texttt{quick\_analysis()}.

\subsubsection{Camada 3: Componentes}

Cada componente é uma unidade independente e testável que implementa
uma responsabilidade específica do sistema. Esta arquitetura baseada em
componentes permite:

\begin{itemize}
	\item \textbf{Modularidade}: componentes podem ser usados independentemente
	\item \textbf{Testabilidade}: cada componente possui testes isolados
	\item \textbf{Manutenibilidade}: mudanças em um componente não afetam outros
	\item \textbf{Extensibilidade}: novos componentes podem ser adicionados sem modificar existentes
\end{itemize}

\subsubsection{Camada 4: Modelos de Dados}

Define estruturas de dados fortemente tipadas usando Python dataclasses,
garantindo type safety e auto-documentação. Estas classes servem como
contratos de interface entre os componentes.

\subsubsection{Camada 5: Infraestrutura}

Bibliotecas de terceiros que fornecem funcionalidades fundamentais de
mineração de processos, simulação, análise estatística e manipulação de
dados.

\subsection{Padrões de Projeto Utilizados}

\subsubsection{Padrão Facade (Fachada)}

A classe \texttt{ProcessMiningPipeline} implementa o padrão Facade
\cite{gamma1994design}, fornecendo uma interface unificada e
simplificada para o subsistema complexo de cinco componentes
independentes.

\textbf{Problema}: A utilização direta dos componentes individuais
requer conhecimento detalhado de suas interfaces, dependências e ordem
de execução, aumentando a complexidade para o usuário.

\textbf{Solução}: O facade encapsula a complexidade da orquestração,
oferecendo métodos simples:

\begin{verbatim}
# Interface simplificada
pipeline = ProcessMiningPipeline()
results = pipeline.run_full_pipeline("log.xes")

# Em vez de:
# analyzer = LogAnalyzer()
# profile = analyzer.analyze("log.xes")
# miner = ProcessMiner()
# model = miner.mine_process("log.xes")
# simulator = LogSimulator(config)
# result = simulator.simulate(model)
# validator = LogValidator()
# validation = validator.validate("original.xes", "synthetic.xes")
\end{verbatim}

\textbf{Benefícios}:
\begin{itemize}
	\item Redução da complexidade para o código cliente
	\item Desacoplamento entre cliente e implementação interna
	\item Facilita a orquestração do workflow completo
	\item Permite evolução interna sem quebrar código cliente
\end{itemize}

\subsubsection{Arquitetura Baseada em Componentes}

Cada componente (\texttt{LogAnalyzer}, \texttt{ProcessMiner},
\texttt{LogSimulator}, \texttt{LogValidator}, \texttt{ORECalculator}) é
projetado para ser independente e reutilizável:

\begin{verbatim}
# Cada componente pode ser usado isoladamente
analyzer = LogAnalyzer()
profile = analyzer.analyze("log.xes")

miner = ProcessMiner()
model = miner.mine_process("log.xes")

simulator = LogSimulator(config)
result = simulator.simulate(model)
\end{verbatim}

\textbf{Benefícios}:
\begin{itemize}
	\item Modularidade e coesão alta
	\item Acoplamento baixo entre componentes
	\item Testabilidade independente
	\item Facilita manutenção e evolução
\end{itemize}

\subsubsection{Data Classes para Type Safety}

O sistema utiliza Python dataclasses com type hints para garantir
segurança de tipos e auto-documentação:

\begin{verbatim}
@dataclass
class ProcessModel:
    petri_net: object
    initial_marking: object
    final_marking: object
    activities: Dict[str, ActivityStatistics]
    arrival_rate: float
    median_case_duration: float
    quality_metrics: Dict[str, float]
\end{verbatim}

\textbf{Benefícios}:
\begin{itemize}
	\item Type hints para suporte de IDEs
	\item Código auto-documentado
	\item Validação em tempo de desenvolvimento
	\item Serialização facilitada
\end{itemize}

\subsubsection{Padrão Strategy para Ajuste de Distribuições}

O ajuste de distribuições estatísticas implementa o padrão Strategy,
testando múltiplas estratégias (Normal, Log-Normal, Exponencial) e
selecionando a melhor através do teste de Kolmogorov-Smirnov:

\begin{verbatim}
# Tenta Normal → Log-Normal → Exponencial
# Seleciona melhor via teste KS (maior p-valor)
best_fit = fitter.fit(durations)
\end{verbatim}

\subsection{Arquitetura de Classes}

O sistema é composto por 12 classes principais organizadas em três
grupos: (1) a classe orquestradora ProcessMiningPipeline, (2) cinco
componentes de serviço independentes, e (3) sete classes de modelos de
dados. A Figura~\ref{fig:class_overview} apresenta uma visão geral
simplificada das classes e seus relacionamentos.

\begin{figure}[H]
	\centering
	% TODO: Inserir diagrama overview da arquitetura de classes
	% \includegraphics[width=0.7\textwidth]{figuras/class_overview.png}
	\caption{Visão geral da arquitetura de classes do Sim2Log-Core. Fonte: Autor (2025)}
	\label{fig:class_overview}
\end{figure}

\subsubsection{Classe Orquestradora: ProcessMiningPipeline}

A classe ProcessMiningPipeline implementa o padrão Facade, fornecendo
uma interface unificada para todo o sistema. A
Figura~\ref{fig:class_pipeline} detalha seus atributos e métodos.

\begin{figure}[H]
	\centering
	% TODO: Inserir diagrama detalhado do ProcessMiningPipeline
	\includegraphics[width=0.7\textwidth]{figuras/class_pipeline.png}
	\caption{Classe ProcessMiningPipeline com atributos e métodos detalhados. Fonte: Autor (2025)}
	\label{fig:class_pipeline}
\end{figure}

\subsubsection{Componentes de Serviço}

Os cinco componentes principais (LogAnalyzer, ProcessMiner,
LogSimulator, LogValidator, ORECalculator) são classes independentes,
cada uma responsável por uma etapa específica do processamento. A
Figura~\ref{fig:class_components} apresenta a estrutura detalhada de
cada componente.

\begin{figure}[H]
	\centering
	% TODO: Inserir diagrama detalhado dos componentes
	\includegraphics[width=0.6\textwidth]{figuras/class_components.png}
	\caption{Classes de componentes com métodos principais e LOC. Fonte: Autor (2025)}
	\label{fig:class_components}
\end{figure}

\subsubsection{Modelos de Dados}

As sete dataclasses (LogProfile, ProcessModel, ActivityStatistics,
SimulationConfig, SimulationResult, ValidationResult, OREMetrics)
definem estruturas de dados fortemente tipadas que fluem entre os
componentes. A Figura~\ref{fig:class_models} detalha a estrutura de
cada modelo.

\begin{figure}[H]
	\centering
	% TODO: Inserir diagrama detalhado dos modelos de dados
	\includegraphics[width=0.7\textwidth]{figuras/class_models.png}
	\caption{Classes de modelos de dados com atributos principais. Fonte: Autor (2025)}
	\label{fig:class_models}
\end{figure}

\subsection{Princípios de Design Seguidos}

O desenvolvimento do Sim2Log-Core fundamentou-se em princípios
estabelecidos de engenharia de software:

\begin{table}[htb]
	\centering
	\caption{Princípios de design aplicados no sistema}
	\label{tab:design_principles}
	\begin{tabular}{p{4cm}p{8cm}}
		\hline
		\textbf{Princípio}                             & \textbf{Implementação no Sistema}                                                                           \\
		\hline
		\textbf{Separação de Responsabilidades}        & Cada módulo tem responsabilidade única e bem definida                                                       \\
		\textbf{DRY (Don't Repeat Yourself)}           & Funções comuns centralizadas no módulo utils.py                                                             \\
		\textbf{Aberto/Fechado}                        & Fácil extensão sem modificar código existente (novos componentes podem ser adicionados)                     \\
		\textbf{Inversão de Dependências}              & Componentes dependem de abstrações (dataclasses) não de implementações concretas                            \\
		\textbf{SOLID}                                 & Responsabilidade única, injeção de dependências, segregação de interfaces                                  \\
		\textbf{Fail-Fast}                             & Validações no início de cada método, lançamento de exceções descritivas                                     \\
		\textbf{Composition over Inheritance}          & Pipeline compõe componentes em vez de herança                                                               \\
		\textbf{Single Source of Truth}                & models.py define estruturas de dados usadas por todos                                                       \\
		\textbf{Reproducibility}                       & Seed fixo, versionamento de dependências, logging completo                                                  \\
		\textbf{Graceful Degradation}                  & Sistema funciona mesmo com dados parciais (ex: recursos opcionais, atributos enriquecidos opcionais)        \\
		\hline
	\end{tabular}
\end{table}

\section{Implementação dos Componentes Principais}

Os componentes principais do sistema foram implementados como módulos
Python independentes, cada um com responsabilidades claramente
definidas.

\subsection{Módulo de Análise de Logs}

O módulo de análise (log\_analyzer.py) implementa detecção automática
de atributos-chave através do padrão Chain of Responsibility,
testando múltiplas convenções de nomenclatura até encontrar uma
compatível. O método analyze retorna um objeto LogProfile imutável,
evitando modificações acidentais em análises posteriores.

\subsection{Módulo de Mineração de Processos}

O módulo de mineração (process\_mining.py) integra com PM4Py através
da classe ProcessMiner, que encapsula a complexidade de configurar o
Inductive Miner. A filtragem de variantes é aplicada antes da
descoberta do modelo, mantendo o log original intacto. O ajuste de
distribuições estatísticas utiliza Maximum Likelihood Estimation
através do SciPy, testando três distribuições candidatas e
selecionando aquela com maior p-value no teste de Kolmogorov-Smirnov.

\subsection{Módulo de Simulação}

O módulo de simulação (simulation.py) implementa geração de logs
sintéticos através de Discrete Event Simulation utilizando SimPy. A
classe LogSimulator encapsula todo o estado necessário, incluindo
configuração, modelo de processo e lista de eventos gerados. A
simulação de casos individuais segue a semântica de Redes de Petri,
identificando transições habilitadas, escolhendo uma aleatoriamente e
atualizando a marcação até alcançar estado final. Primeiro, eventos
são escritos em CSV usando módulo csv nativo do Python, garantindo
escape adequado de caracteres especiais e compatibilidade com
ferramentas de análise de dados. Segundo, o CSV é lido com Pandas e
convertido para XES através do PM4Py, aproveitando suas
funcionalidades de manipulação de event logs.

\subsection{Módulo de Validação}

O módulo de validação (validation.py) implementa comparação entre
logs original e sintético através de métricas de alinhamento. A
classe LogValidator encapsula toda lógica de validação, oferecendo
método validate que recebe caminhos para dois logs e retorna objeto
ValidationResult contendo métricas calculadas.

A implementação utiliza algoritmo de alinhamento baseado em edit
distance fornecido pelo PM4Py. Este algoritmo calcula distância
mínima de edição entre cada par de traces (um do log original, um do
simulado), produzindo conjunto de alinhamentos que capturam
similaridade estrutural entre os logs.

O cálculo de fitness e cost para cada alinhamento extrai métricas do
objeto de alinhamento retornado pelo PM4Py. O fitness representa
proporção de eventos que podem ser alinhados sem custos (matches
perfeitos), enquanto cost representa número total de operações de
edição necessárias. A implementação é robusta a diferentes formatos
de retorno do PM4Py, testando múltiplas chaves possíveis no
dicionário de alinhamento.

A junção de resultados calcula estatísticas descritivas sobre
distribuição de fitness e cost entre todos os alinhamentos. Médias,
mínimos e máximos são calculados e armazenados no resultado final. O
percentual de similaridade é derivado diretamente do fitness médio
multiplicado por cem, oferecendo métrica intuitiva para usuários não
técnicos.

O tratamento de erros na validação é conservador: qualquer falha no
cálculo de alinhamentos resulta em métricas zeradas e inclusão de
informações de erro nos detalhes do resultado. Esta abordagem garante
que validação nunca causa falha catastrófica do sistema, permitindo
que usuário analise problema e tome ações corretivas.

\section{Implementação da Interface de Usuário}

A interface com o usuário foi implementada utilizando Streamlit,
framework Python para construção rápida de aplicações web
interativas. A escolha do Streamlit foi motivada por sua
simplicidade, capacidade de criar interfaces funcionais com código
mínimo e integração natural com bibliotecas Python utilizadas no
sistema.

\subsection{Tecnologias Utilizadas}

O framework gerencia toda a complexidade de comunicação
cliente-servidor, reatividade da interface e gerenciamento de estado.
O gerenciamento de estado persistente entre reexecuções utiliza
st.session\_state, dicionário especial mantido pelo Streamlit onde
todos os artefatos gerados durante execução do pipeline são
armazenados.

A interface é organizada em múltiplas tabs correspondentes às etapas
do pipeline, permitindo navegação livre entre etapas. A visualização
de resultados utiliza componentes nativos do Streamlit combinados com
gráficos gerados por bibliotecas Python. Métricas são exibidas usando
st.metric, gráficos de barras utilizam st.bar\_chart e tabelas são
renderizadas com st.dataframe.

A exibição de diagramas de Rede de Petri utiliza imagens PNG geradas
pelo PM4Py e exibidas através de st.image. O upload de arquivos
utiliza st.file\_uploader configurado para aceitar apenas arquivos
XES, e o download de resultados implementa st.download\_button para
cada arquivo gerado. O feedback ao usuário durante operações longas
utiliza st.spinner com indicador de progresso animado. A figura a
seguir ilustra a interface do usuário:

\begin{figure}[htb]
	\centering
	\includegraphics[width=\textwidth]{figuras/fig3.png}
	\caption{Interface do usuário. Fonte: Autor (2025)}
	\label{fig:interface_usuario}
\end{figure}
\clearpage

\section{Testes e Validação}

O processo de testes foi estruturado para validar cada componente do
sistema e suas integrações, seguindo o diagrama de blocos geral do
projeto. Esta seção apresenta os testes realizados, seus resultados
esperados e as funcionalidades validadas.

\subsection{Teste de Análise Automática de Logs}

\textbf{Descrição:} Teste da funcionalidade de detecção automática de atributos-chave e coleta de estatísticas estruturais de logs XES.

\textbf{Resultado Esperado:} O sistema deve detectar corretamente os atributos case\_id, activity\_name e timestamp, extrair estatísticas como número de casos, atividades únicas, variantes e distribuição de durações.

\textbf{Funcionalidade Validada:} Etapa 1 do pipeline - Análise Automática de Logs, incluindo detecção de atributos-chave e coleta de estatísticas estruturais e temporais.

\subsection{Teste de Mineração de Processos}

\textbf{Descrição:} Teste da descoberta de modelo de processo através do Inductive Miner e ajuste de distribuições estatísticas.

\textbf{Resultado Esperado:} Geração de Rede de Petri válida, estatísticas de atividades com distribuições ajustadas (Normal, Log-Normal ou Exponencial) e métricas de qualidade (fitness > 0.7).

\textbf{Funcionalidade Validada:} Etapa 2 do pipeline - Mineração de Processos, incluindo filtragem de variantes, descoberta do modelo e extração de estatísticas temporais.

\subsection{Teste de Simulação de Logs Sintéticos}

\textbf{Descrição:} Teste da geração de casos sintéticos utilizando Discrete Event Simulation baseada na Rede de Petri descoberta.

\textbf{Resultado Esperado:} Geração de log sintético em formato XES com número de casos e eventos conforme parâmetros configurados, mantendo estrutura temporal similar ao log original.

\textbf{Funcionalidade Validada:} Etapa 3 do pipeline - Simulação de Logs Sintéticos, incluindo configuração da simulação, geração de casos e produção de logs de saída.

\subsection{Teste de Validação de Qualidade}

\textbf{Descrição:} Teste da comparação entre log original e sintético através de alinhamento de traces e cálculo de métricas de similaridade.

\textbf{Resultado Esperado:} Métricas de alinhamento indicando similaridade adequada (fitness médio > 0.7) entre logs original e sintético.

\textbf{Funcionalidade Validada:} Etapa 4 do pipeline - Validação de Qualidade, incluindo alinhamento de traces e cálculo de métricas de similaridade.

\subsection{Teste de Integração Completa}

\textbf{Descrição:} Teste de ponta-a-ponta executando o pipeline completo com log de exemplo (running-example.xes).

\textbf{Resultado Esperado:} Execução bem-sucedida de todas as etapas sem erros, produção de resultados dentro dos ranges esperados e tempo de execução aceitável.

\textbf{Funcionalidade Validada:} Integração completa entre todas as etapas do pipeline, validando fluxo de dados e arquitetura geral do sistema.

\subsection{Teste de Interface de Usuário}

\textbf{Descrição:} Teste da interface Streamlit incluindo upload de arquivos, navegação entre tabs, visualização de resultados e download de arquivos gerados.

\textbf{Resultado Esperado:} Interface responsiva e intuitiva, upload e processamento de arquivos XES, visualização adequada de métricas e diagramas, download funcional dos resultados.

\textbf{Funcionalidade Validada:} Interface de usuário completa, incluindo gerenciamento de estado, visualização de resultados e interação com o pipeline através da interface web.

\section{Resultados Esperados e Obtidos}

\subsection{Resultados Esperados}

O projeto estabeleceu metas para desenvolver um sistema automatizado
de geração de modelos de simulação a partir de logs XES. Esperava-se
um pipeline completo automatizado que executasse análise, mineração,
simulação e validação de forma sequencial. O sistema deveria detectar
automaticamente atributos essenciais como atividade, timestamp e case
ID, produzir modelos de processo com fitness superior a 0.7 e gerar
logs sintéticos com similaridade acima de 0.7 ao original.

Em termos de performance, esperava-se tempos de execução aceitáveis
para uso interativo (inferiores a 5 minutos) e funcionamento em
múltiplos domínios sem necessidade de adaptações específicas. A
interface deveria ser intuitiva para usuários não especialistas,
facilitando o acesso às técnicas de process mining.

\subsection{Resultados Obtidos}

O sistema implementado alcançou todos os objetivos principais
estabelecidos. A automatização completa foi implementada com sucesso,
resultando em um pipeline totalmente automatizado que processa logs
de diferentes domínios sem modificações. Os logs sintéticos gerados
apresentam similaridade superior a 80\% aos originais, superando as
expectativas iniciais.

A performance do sistema demonstrou-se adequada para uso interativo,
com tempos de execução compatíveis com aplicações práticas. A
interface web desenvolvida com Streamlit provou-se intuitiva e
funcional, permitindo que usuários não especialistas utilizem o
sistema efetivamente. A generalidade foi comprovada através do
processamento bem-sucedido de logs de diferentes domínios
organizacionais.

\subsection{Limitações Identificadas}

Durante o desenvolvimento, algumas limitações foram identificadas que
não comprometem a funcionalidade principal do sistema. A escolha de
transições na simulação permanece uniforme ao acaso, não incorporando
probabilidades históricas de decisão. Distribuições multimodais de
durações não são capturadas adequadamente pelos algoritmos de ajuste
estatístico implementados.

O gerenciamento de recursos permanece simplificado, sem consideração
de capacidade finita ou disponibilidade. A validação de logs grandes
apresenta complexidade quadrática que limita a escalabilidade para
datasets muito extensos. Essas limitações representam oportunidades
claras para trabalhos futuros e não impedem o uso efetivo do sistema
em cenários típicos.
% ----------------------------------------------------------
% Conclusão
% ----------------------------------------------------------
